{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wooden-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stone-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understanding-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedded-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Churn Ratio i.e. the retension ratio. Probability of staying for a member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detected-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automotive-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fitting-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worst-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding\n",
    "geo = pd.get_dummies(dataset['Geography'], drop_first=True)\n",
    "gender = pd.get_dummies(dataset['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reasonable-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,geo,gender], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0                  1        101348.88        0      0     0  \n",
       "1                  1        112542.58        0      1     0  \n",
       "2                  0        113931.57        0      0     0  \n",
       "3                  0         93826.63        0      0     0  \n",
       "4                  1         79084.10        0      1     0  \n",
       "...              ...              ...      ...    ...   ...  \n",
       "9995               0         96270.64        0      0     1  \n",
       "9996               1        101699.77        0      0     1  \n",
       "9997               1         42085.58        0      0     0  \n",
       "9998               0         92888.52        1      0     1  \n",
       "9999               0         38190.78        0      0     0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "great-process",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "severe-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "favorite-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civil-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intelligent-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mineral-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "architectural-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spectacular-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unlike-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first layer: hidden layer\n",
    "model.add(Dense(units=8, activation='relu', input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sunset-decrease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "other-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "straight-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 150\n",
      "Trainable params: 150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "close-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "diverse-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "=================================================================\n",
      "Total params: 192\n",
      "Trainable params: 192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "continued-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer: Binary classification, only 2 values : sigmoid function\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "verbal-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "conceptual-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'units': 8,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "committed-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "subsequent-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "piano-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.2833675 , -0.48221347,  0.01208109, -0.17726353, -0.18159577,\n",
       "          0.22982174, -0.4351846 , -0.26548353],\n",
       "        [-0.4934908 , -0.25415018,  0.24879986,  0.11662298,  0.16775352,\n",
       "          0.33291882,  0.02848196,  0.30530763],\n",
       "        [-0.07468215,  0.18980956, -0.5433398 ,  0.47336155, -0.12448037,\n",
       "          0.53765434,  0.52257365,  0.10329068],\n",
       "        [ 0.07633209,  0.3540212 , -0.5600941 ,  0.53058153, -0.14589047,\n",
       "          0.08886802,  0.21116722, -0.51653194],\n",
       "        [-0.4532232 , -0.07622477,  0.46867186, -0.11477154, -0.41184253,\n",
       "          0.23033059, -0.13412529,  0.06323087],\n",
       "        [-0.3788827 , -0.48469502, -0.29307973,  0.54888755, -0.00488222,\n",
       "         -0.53939706,  0.18319654,  0.37579352],\n",
       "        [-0.4778969 , -0.5207247 ,  0.12242943,  0.37289435, -0.13424924,\n",
       "          0.5325627 ,  0.17406636, -0.2353704 ],\n",
       "        [ 0.50732297, -0.14120024, -0.37019962,  0.09214693, -0.54273903,\n",
       "          0.2690825 , -0.51683956, -0.467516  ],\n",
       "        [-0.56074965,  0.50032204,  0.36203676, -0.5521625 , -0.5596859 ,\n",
       "          0.00584984,  0.4374184 ,  0.49475354],\n",
       "        [ 0.10102147, -0.40274394,  0.34381074,  0.47323686,  0.4966964 ,\n",
       "          0.2258277 , -0.5321005 ,  0.06067282],\n",
       "        [ 0.22072321,  0.4980114 , -0.3448102 ,  0.22154528, -0.06936061,\n",
       "          0.09077483, -0.5527706 ,  0.48834938]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.0192349 , -0.40293792,  0.39175904, -0.34267527,  0.04874009,\n",
       "          0.02740854],\n",
       "        [ 0.38650346, -0.19563815,  0.40311193, -0.43590564,  0.47123206,\n",
       "         -0.28903082],\n",
       "        [ 0.38918853, -0.05807453,  0.4455124 ,  0.26793277, -0.64311844,\n",
       "          0.2232933 ],\n",
       "        [-0.20280635,  0.37917352, -0.21900699,  0.20139289,  0.5872812 ,\n",
       "         -0.21307293],\n",
       "        [ 0.23116171, -0.04142326, -0.41584617,  0.05838233, -0.5745928 ,\n",
       "          0.60872054],\n",
       "        [ 0.1737886 ,  0.06159836,  0.10787612, -0.2959594 , -0.42412788,\n",
       "         -0.43600973],\n",
       "        [ 0.02508825, -0.6061689 , -0.25964627, -0.24042496, -0.61866295,\n",
       "         -0.25652745],\n",
       "        [-0.36676726,  0.55328786,  0.46737063,  0.4060831 ,  0.2741533 ,\n",
       "         -0.4579445 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.48612005, -0.5466114 ,  0.1583041 ,  0.61402255, -0.22159582,\n",
       "          0.5076962 ],\n",
       "        [-0.1702773 ,  0.6935933 , -0.16554475, -0.39428225,  0.23743951,\n",
       "          0.13109052],\n",
       "        [-0.00114757, -0.06374913,  0.30595678, -0.63930196,  0.63485664,\n",
       "         -0.03183573],\n",
       "        [ 0.6720113 ,  0.08381224,  0.67790323, -0.47970816,  0.29964823,\n",
       "          0.46373218],\n",
       "        [ 0.07231677, -0.36670843, -0.2615406 , -0.6407496 ,  0.3942296 ,\n",
       "          0.5260344 ],\n",
       "        [ 0.5166362 ,  0.54071444, -0.25120366,  0.15988004,  0.08225328,\n",
       "          0.6094075 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.69647884],\n",
       "        [ 0.5415653 ],\n",
       "        [ 0.09647715],\n",
       "        [-0.55768627],\n",
       "        [ 0.01862144],\n",
       "        [ 0.49378395]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "theoretical-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 425.2488\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 11.5578\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.9178\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.3919\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.1241\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.8960\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 8.3932\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.0191\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.6275\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.1679\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.1177\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.2821\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.5677\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.1769\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.8880\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.9416\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.6310\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.6452\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.7770\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.3430\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.6727\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.3641\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.3753\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.6147A: 0s - loss: 3.\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.1186\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.4829\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 4.2600\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.9915\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.3688\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.4277\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.5669\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.9181\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.4747\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.8013\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 0s 954us/step - loss: 2.6229\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.7912\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.3212\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.7931\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.8721\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.5623\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 0s 993us/step - loss: 3.8569\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 0s 957us/step - loss: 2.8439\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 0s 969us/step - loss: 2.3855\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 0s 989us/step - loss: 2.7418\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.7993\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.7614\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.1322\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.0761\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.0931\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.0943\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.9345\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4268\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.8547\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0272\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0018\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9217\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9140\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7707\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7835\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7922\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8763\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8583\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9886\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7508\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8212\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.7638\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7731\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7194\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8110\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9050\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8088\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6465\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6012\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6841\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9581\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6352\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6021\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.6066\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.5426\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5173\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.5202\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.5130\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.5117\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5117\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5536\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5162\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5053\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5045\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5033\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5093\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5069\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5061\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5061\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5061\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5101\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5069\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065A: 0s - loss: 0.\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5064\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5060\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5070\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5062\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5082\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5075\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5070\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5068\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5068\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5065\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064A: 0s - loss: 0.5\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5068\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5073\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5071\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5063\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5103\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5065\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5067\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5067\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2020fbcaa90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "democratic-occupation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [425.2488098144531,\n",
       "  11.557760238647461,\n",
       "  8.917825698852539,\n",
       "  6.39191198348999,\n",
       "  7.124133586883545,\n",
       "  7.895970821380615,\n",
       "  8.393240928649902,\n",
       "  7.01906681060791,\n",
       "  6.627538204193115,\n",
       "  7.167882442474365,\n",
       "  6.117731094360352,\n",
       "  5.282078266143799,\n",
       "  6.567655563354492,\n",
       "  6.176915645599365,\n",
       "  4.887979507446289,\n",
       "  5.9416279792785645,\n",
       "  5.6309590339660645,\n",
       "  4.645229816436768,\n",
       "  4.776954174041748,\n",
       "  8.343009948730469,\n",
       "  4.672668933868408,\n",
       "  6.364073753356934,\n",
       "  5.375340938568115,\n",
       "  3.6147382259368896,\n",
       "  4.118622303009033,\n",
       "  4.482852935791016,\n",
       "  4.260013103485107,\n",
       "  3.991514205932617,\n",
       "  4.368829250335693,\n",
       "  3.4277119636535645,\n",
       "  3.566861867904663,\n",
       "  3.918130397796631,\n",
       "  3.4747378826141357,\n",
       "  2.8012826442718506,\n",
       "  2.622875690460205,\n",
       "  3.7912025451660156,\n",
       "  2.321214437484741,\n",
       "  2.7931010723114014,\n",
       "  2.8720734119415283,\n",
       "  3.5622963905334473,\n",
       "  3.856902599334717,\n",
       "  2.8439393043518066,\n",
       "  2.385547637939453,\n",
       "  2.7418320178985596,\n",
       "  2.799258232116699,\n",
       "  1.7613974809646606,\n",
       "  2.132150650024414,\n",
       "  2.0761473178863525,\n",
       "  2.0931203365325928,\n",
       "  2.0943241119384766,\n",
       "  1.9345332384109497,\n",
       "  1.4267566204071045,\n",
       "  1.8546658754348755,\n",
       "  1.0271528959274292,\n",
       "  1.001825213432312,\n",
       "  0.9216873049736023,\n",
       "  0.9140424728393555,\n",
       "  0.7707339525222778,\n",
       "  0.7834914922714233,\n",
       "  0.7922467589378357,\n",
       "  0.8763107657432556,\n",
       "  0.8582900762557983,\n",
       "  0.9885662794113159,\n",
       "  0.7507832050323486,\n",
       "  0.8212450742721558,\n",
       "  0.7637936472892761,\n",
       "  0.7730684280395508,\n",
       "  0.719382643699646,\n",
       "  0.8109570741653442,\n",
       "  0.9049769639968872,\n",
       "  0.8088275790214539,\n",
       "  0.6464629769325256,\n",
       "  0.6012480854988098,\n",
       "  0.6840975880622864,\n",
       "  0.9580821990966797,\n",
       "  0.6352283358573914,\n",
       "  0.6021071672439575,\n",
       "  0.6066039800643921,\n",
       "  0.5425565242767334,\n",
       "  0.5173081159591675,\n",
       "  0.5202298760414124,\n",
       "  0.5130003690719604,\n",
       "  0.5116685032844543,\n",
       "  0.5117457509040833,\n",
       "  0.5536105632781982,\n",
       "  0.5161758661270142,\n",
       "  0.5052872896194458,\n",
       "  0.5045198202133179,\n",
       "  0.5032758116722107,\n",
       "  0.5092722177505493,\n",
       "  0.5069199800491333,\n",
       "  0.5064714550971985,\n",
       "  0.5064148902893066,\n",
       "  0.5064243078231812,\n",
       "  0.5063930153846741,\n",
       "  0.5064026713371277,\n",
       "  0.5063773989677429,\n",
       "  0.5063459873199463,\n",
       "  0.5062503814697266,\n",
       "  0.506064236164093,\n",
       "  0.5061045289039612,\n",
       "  0.5063251256942749,\n",
       "  0.5062856078147888,\n",
       "  0.5061298608779907,\n",
       "  0.5101420879364014,\n",
       "  0.5069352388381958,\n",
       "  0.5065557956695557,\n",
       "  0.506525456905365,\n",
       "  0.5065287351608276,\n",
       "  0.5065000653266907,\n",
       "  0.5065113306045532,\n",
       "  0.5064998865127563,\n",
       "  0.5065251588821411,\n",
       "  0.5064818859100342,\n",
       "  0.5065031051635742,\n",
       "  0.5065218210220337,\n",
       "  0.5064845085144043,\n",
       "  0.5064798593521118,\n",
       "  0.5064619183540344,\n",
       "  0.5064594745635986,\n",
       "  0.5065479874610901,\n",
       "  0.5064617991447449,\n",
       "  0.5064367651939392,\n",
       "  0.5064006447792053,\n",
       "  0.5060179233551025,\n",
       "  0.5070343017578125,\n",
       "  0.5063367486000061,\n",
       "  0.5062501430511475,\n",
       "  0.5062294602394104,\n",
       "  0.5081955790519714,\n",
       "  0.5075448751449585,\n",
       "  0.5070089101791382,\n",
       "  0.5068355798721313,\n",
       "  0.5068007111549377,\n",
       "  0.5066078901290894,\n",
       "  0.5064810514450073,\n",
       "  0.5064905285835266,\n",
       "  0.50644850730896,\n",
       "  0.5065364241600037,\n",
       "  0.5065405964851379,\n",
       "  0.5065093636512756,\n",
       "  0.5064802765846252,\n",
       "  0.5064662098884583,\n",
       "  0.5064718723297119,\n",
       "  0.5065653324127197,\n",
       "  0.5064481496810913,\n",
       "  0.5065217614173889,\n",
       "  0.5064062476158142,\n",
       "  0.5066039562225342,\n",
       "  0.5066431164741516,\n",
       "  0.5066346526145935,\n",
       "  0.5066190958023071,\n",
       "  0.506547212600708,\n",
       "  0.5065407752990723,\n",
       "  0.5066168308258057,\n",
       "  0.5065367817878723,\n",
       "  0.5066110491752625,\n",
       "  0.5066302418708801,\n",
       "  0.5067037343978882,\n",
       "  0.5065946578979492,\n",
       "  0.5065840482711792,\n",
       "  0.5066260099411011,\n",
       "  0.5065624117851257,\n",
       "  0.5067982077598572,\n",
       "  0.5073307156562805,\n",
       "  0.5071274638175964,\n",
       "  0.5066640377044678,\n",
       "  0.506605863571167,\n",
       "  0.5064959526062012,\n",
       "  0.506476640701294,\n",
       "  0.5064429044723511,\n",
       "  0.5064478516578674,\n",
       "  0.5065842866897583,\n",
       "  0.5065774917602539,\n",
       "  0.506607174873352,\n",
       "  0.5064087510108948,\n",
       "  0.5063404440879822,\n",
       "  0.5065566301345825,\n",
       "  0.5064897537231445,\n",
       "  0.506515383720398,\n",
       "  0.5102970600128174,\n",
       "  0.5067216753959656,\n",
       "  0.5066125392913818,\n",
       "  0.5066090226173401,\n",
       "  0.5065878033638,\n",
       "  0.5065615773200989,\n",
       "  0.5065440535545349,\n",
       "  0.5066199898719788,\n",
       "  0.5066394805908203,\n",
       "  0.506657600402832,\n",
       "  0.5066540837287903,\n",
       "  0.506641149520874,\n",
       "  0.5066592693328857,\n",
       "  0.506636381149292,\n",
       "  0.5066521763801575,\n",
       "  0.5066908597946167,\n",
       "  0.5066475868225098,\n",
       "  0.5066240429878235,\n",
       "  0.5066709518432617,\n",
       "  0.5066421627998352]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hybrid-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "tutorial-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "recent-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dominant-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first layer: hidden layer\n",
    "model.add(Dense(units=8, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "# Output layer: Binary classification, only 2 values : sigmoid function\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "selected-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam( learning_rate=0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "julian-bonus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3192.3064\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3163.4529\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3134.7659\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3106.2317\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3079.2881\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3056.2629\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3034.0107\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3011.9399\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2989.9382\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2967.9639\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2945.9827\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2923.9719\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2901.9590\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2879.9507\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2857.9409\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2835.9443\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2814.0107\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2792.1055\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2770.2195\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2748.3518\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2726.5190\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2704.7249\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2682.9680\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2661.2639\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2639.5950\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2617.9885\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2596.4766\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2575.0024\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2553.5632\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2532.1812\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2510.8711\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2489.6465\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2468.4980\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2447.4092\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2426.3511\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2405.3516\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2384.3979\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2363.4990\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2342.6606\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2321.8730\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2301.1455\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2280.4819\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2259.8796\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2239.3247\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2218.8162\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2198.3479\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2177.8911\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2157.4646\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2137.1135\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2116.7920\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2096.4795\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2076.1956\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2055.9287\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2035.6982\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2015.4955\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1995.3105\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1975.1205\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1954.9191\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1934.7217\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1914.5098\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1894.3074\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1874.1179\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1853.9410\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1833.8073\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1813.6437\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1793.5231\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1773.4301\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1753.3528\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1733.3228\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1713.3582\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1693.4707\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1673.6877\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1654.0353\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1634.5830\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1615.4087\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1596.6678\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1578.6714\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1562.0020\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1546.9646\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1532.8362\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1518.9542\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 0s 944us/step - loss: 1505.1342\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 0s 948us/step - loss: 1491.3286\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1477.5731\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1463.8473\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1450.1387\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1436.4430\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1422.7202\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1409.0060\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1395.3214\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1381.6686\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1368.0598\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1354.5209\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1341.0343\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1327.6141\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 1314.2556\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1300.9489\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1287.6782\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1274.4352\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1261.2300\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1248.0643\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1234.9509\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1221.9147\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1208.9542\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1196.0688\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1183.2415\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1170.4274\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1157.6548\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1144.9423\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1132.2946\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1119.7345\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1107.2485\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1094.8175\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1082.4143\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1070.0479\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1057.7430\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1045.5056\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1033.3684\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1021.3519\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1009.4464\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 997.5890\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 985.7497\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 973.9546\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 962.2291\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 950.5451\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 938.9418\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 927.4378\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 916.0045\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 904.6121\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 0s 993us/step - loss: 893.2690\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 881.9911\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 870.7897\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 859.6354\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 848.5263\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 837.4977\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 826.5198\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 815.6326\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 804.8162\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 794.0599\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 783.3734\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 772.7529\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 762.1856\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 0s 997us/step - loss: 751.7154\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 741.3197\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 730.9709\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 720.7125\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 710.5147\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 700.3914\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 690.3484\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 680.3366\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 670.4203\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 660.5674\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 650.8052\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 641.1210\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 631.4924\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 621.9473\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 612.4957\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 603.1176\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 593.8002\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 584.5523\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 575.3870\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 566.3259\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 557.3461\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 548.4216\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 539.5646\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 530.7802\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 527.221 - 0s 1ms/step - loss: 522.0711\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 0s 981us/step - loss: 513.4316\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 504.8382\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 496.2944\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 487.8220\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 479.4115\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 471.0775\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 462.8227\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 454.6381\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 446.5420\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 438.5405\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 430.6288\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 422.7909\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 415.0112\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 407.3035\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 399.6626\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 392.0866\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 384.5690\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 377.1273\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 369.7653\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 362.4664\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 355.2316\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 348.0679\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 340.9585\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 333.9236\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 326.9728\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 320.0721\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 313.2210\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 306.4296\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 299.6929\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 293.0164\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 286.4178\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 279.8620\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 273.3427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20211e95c10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "nonprofit-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deadly-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
